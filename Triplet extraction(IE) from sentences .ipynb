{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "athletic-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, pandas as pd, numpy as np\n",
    "from nltk.parse.corenlp import CoreNLPParser, CoreNLPDependencyParser\n",
    "from nltk.tree import ParentedTree\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "turkish-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_parser = CoreNLPDependencyParser(url='http://0.0.0.0:9000')\n",
    "pos_tagger = CoreNLPParser(url='http://0.0.0.0:9000', tagtype='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beautiful-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence (input_sent):\n",
    "    # Parse sentence using Stanford CoreNLP Parser\n",
    "    pos_type = pos_tagger.tag(input_sent.split())\n",
    "    parse_tree, = ParentedTree.convert(list(pos_tagger.parse(input_sent.split()))[0])\n",
    "    dep_type, = ParentedTree.convert(dep_parser.parse(input_sent.split()))\n",
    "    return pos_type, parse_tree, dep_type\n",
    "\n",
    "def multi_liaison (input_sent, output=['tagging','parse_tree','type_dep','spo','relation']):\n",
    "    pos_type, parse_tree, dep_type = convert_sentence(input_sent)\n",
    "    pos_sent = ' '.join([x[0]+'/'+x[1] for x in pos_type])\n",
    "    # Extract subject, predicate and object\n",
    "    subject, adjective = get_subject(parse_tree)\n",
    "    predicate = get_predicate(parse_tree)\n",
    "    objects = get_object(parse_tree)\n",
    "    # Generate the relations between subjects and objects\n",
    "    relation = get_relationship(dep_type, subject, predicate, objects)\n",
    "    if 'tagging' in output:\n",
    "        print('---TAGGING---')\n",
    "        print(pos_sent)\n",
    "        print()\n",
    "    if 'parse_tree' in output:\n",
    "        print('---PARSE TREE---')\n",
    "        parse_tree.pretty_print()\n",
    "        print()\n",
    "    if 'type_dep' in output:\n",
    "        print('---TYPED DEPENDENCIES---')\n",
    "        for x in dep_type.triples(): print(x) \n",
    "        print()\n",
    "    if 'spo' in output:\n",
    "        print('---MULTI-LIAISON OUTPUT---')\n",
    "        print('Subject: ',len(subject))\n",
    "        for x in subject: print(' '.join(x))\n",
    "        print('Predicate: ',len(predicate))\n",
    "        for x in predicate: print(' '.join(x))\n",
    "        print('Object: ',len(objects))\n",
    "        for x in objects: print(' '.join(x))\n",
    "        print()\n",
    "    if 'relation' in output:\n",
    "        print('---RELATIONSHIP---')\n",
    "        for x in relation: print(x)\n",
    "\n",
    "def get_subject (parse_tree):\n",
    "    # Extract the nouns and adjectives from NP_subtree which is before the first / main VP_subtree\n",
    "    subject, adjective = [],[]\n",
    "    for s in parse_tree:\n",
    "        if s.label() == 'NP':\n",
    "            for t in s.subtrees(lambda y: y.label() in ['NN','NNP','NNS','NNPS','PRP']):\n",
    "                # Avoid empty or repeated values\n",
    "                if t.pos()[0] not in subject:\n",
    "                    subject.append(t.pos()[0])\n",
    "            for t in s.subtrees(lambda y: y.label().startswith('JJ')):\n",
    "                if t.pos()[0] not in adjective:\n",
    "                    adjective.append(t.pos()[0])\n",
    "    return subject, adjective\n",
    "\n",
    "def get_predicate (parse_tree):\n",
    "    # Extract the verbs from the VP_subtree\n",
    "    predicate = []\n",
    "    for s in parse_tree.subtrees(lambda x: x.label() == 'VP'):\n",
    "        for t in s.subtrees(lambda y: y.label().startswith('VB')):\n",
    "            if t.pos()[0] not in predicate:\n",
    "                predicate.append(t.pos()[0]) \n",
    "    return predicate\n",
    "\n",
    "def get_object (parse_tree):\n",
    "    # Extract the nouns from VP_NP_subtree\n",
    "    objects, output = [],[]\n",
    "    for s in parse_tree.subtrees(lambda x: x.label() == 'VP'):\n",
    "        for t in s.subtrees(lambda y: y.label() == 'NP'):\n",
    "            for u in t.subtrees(lambda z: z.label() in ['NN','NNP','NNS','NNPS','PRP$']):\n",
    "                output = u.pos()[0]\n",
    "                if u.left_sibling() is not None and u.left_sibling().label().startswith('JJ'):\n",
    "                    output += u.left_sibling().pos()[0]\n",
    "                if output not in objects:\n",
    "                    objects.append(output)\n",
    "    return objects\n",
    "\n",
    "def get_relationship (dep_type, subject, predicate, objects):\n",
    "    # Generate relations based on the relationship dependencies obtained from parse_tree.triples()\n",
    "    subject = [x[0] for x in subject]\n",
    "    predicate = [x[0] for x in predicate]\n",
    "    objects = [x[0] for x in objects]     \n",
    "    d1, d2, r1, r2, relation, s1, s2, subjs = [],[],[],[],[],[],[],[]\n",
    "    w1, w2, output = '','',''\n",
    "    for head, rel, dep in dep_type.triples():\n",
    "        if rel in ['nsubj','acl:relcl','conj']:\n",
    "            s1, s2 = head[0], dep[0]\n",
    "            if s2 in subject and s1 in predicate:\n",
    "                w1, w2 = s2, s1\n",
    "            elif s2 in predicate and (s1 in subject or s1 in objects):\n",
    "                w1, w2 = s1, s2\n",
    "            elif s2 in subject and s1 in subject:\n",
    "                subjs = [s1, s2]\n",
    "            if w1 != '' and w2 != '':\n",
    "                r1 = [w1, w2]\n",
    "        if rel in ['dobj','prep','nmod','conj']:\n",
    "            d1, d2 = head[0], dep[0]\n",
    "            if d1 in objects and d2 in objects: \n",
    "                r2 = [d1,d2]\n",
    "            elif d2 in objects:\n",
    "                r2 = [d2]\n",
    "            elif d1 in objects:\n",
    "                r2 = [d1]\n",
    "        if len(r1) != 0 and len(r2) != 0 and (r2[0] not in r1 and r2[-1] not in r1):\n",
    "            if len(subjs) != 0:\n",
    "                for n in subjs:\n",
    "                    output = '-'.join([n] + r1[-1:] + r2)\n",
    "                    if output not in relation:\n",
    "                        relation.append(output)\n",
    "            else:\n",
    "                output = '-'.join(r1+r2)\n",
    "                if output not in relation:\n",
    "                    relation.append(output)  \n",
    "    rm = [x for x in relation for y in relation if x != y and re.match(x,y)]\n",
    "    for x in rm: relation.remove(x)    \n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "czech-vertical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TAGGING---\n",
      "He/PRP went/VBD to/IN London/NNP University/NNP for/IN his/PRP$ education/NN\n",
      "\n",
      "---PARSE TREE---\n",
      "     S                                                   \n",
      "  ___|____                                                \n",
      " |        VP                                             \n",
      " |    ____|_________________                              \n",
      " |   |                      PP                           \n",
      " |   |     _________________|_______                      \n",
      " |   |    |                         NP                   \n",
      " |   |    |           ______________|___                  \n",
      " |   |    |          |                  PP               \n",
      " |   |    |          |               ___|____             \n",
      " NP  |    |          NP             |        NP          \n",
      " |   |    |     _____|______        |    ____|______      \n",
      "PRP VBD   IN  NNP          NNP      IN PRP$         NN   \n",
      " |   |    |    |            |       |   |           |     \n",
      " He went  to London     University for his      education\n",
      "\n",
      "\n",
      "---TYPED DEPENDENCIES---\n",
      "(('went', 'VBD'), 'nsubj', ('He', 'PRP'))\n",
      "(('went', 'VBD'), 'obl', ('University', 'NNP'))\n",
      "(('University', 'NNP'), 'case', ('to', 'IN'))\n",
      "(('University', 'NNP'), 'compound', ('London', 'NNP'))\n",
      "(('went', 'VBD'), 'obl', ('education', 'NN'))\n",
      "(('education', 'NN'), 'case', ('for', 'IN'))\n",
      "(('education', 'NN'), 'nmod:poss', ('his', 'PRP$'))\n",
      "\n",
      "---MULTI-LIAISON OUTPUT---\n",
      "Subject:  1\n",
      "He PRP\n",
      "Predicate:  1\n",
      "went VBD\n",
      "Object:  4\n",
      "London NNP\n",
      "University NNP\n",
      "his PRP$\n",
      "education NN\n",
      "\n",
      "---RELATIONSHIP---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "multi_liaison('He went to London University for his education')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-killing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
